# config.yaml (refactored)
# Weights & Biases Configuration
wandb:
  enabled: true
  project: "eeg-spindle-detection"
  entity: null        # Set your wandb username/team (if applicable)
  tags: ["eeg", "spindle-detection", "time-based"]
  notes: "Time-based analysis with configurable thresholds"
  mode: "online"      # online, offline, disabled

# Data Configuration
data:
  edf_path: "data/raw/P002_1_raw.edf"
  json_path: "data/labels/sleep_block_spindle_output_P002_1.json"
  save_dir: "data/processed"
  results_dir: "results"
  model_dir: "models"

  # EEG Channels
  eeg_channels: ["F3", "F4", "C3", "C4", "O1", "O2", "P3", "P4", "T3", "T4", "F7", "F8", "T5", "T6", "Fz", "Cz"]

  # Time splits (in hours)
  train_start: 0.0
  train_end: 6.0
  val_start: 6.0
  val_end: 7.0
  test_start: 7.0
  test_end: 8.0

# Preprocessing Configuration (time-based processing parameters)
preprocessing:
  filter_low: 5.0
  filter_high: 30.0
  window_sec: 2.0
  step_sec: 0.1              # 90% overlap for smooth time-based predictions
  overlap_threshold: 0.7
  downsample_majority: true  # downsample majority class in training if true

  # Time-based analysis parameters
  time_resolution: 0.1       # seconds – resolution for time-based predictions
  smoothing_window: 1.0      # seconds – smoothing window for probability timeline
  min_spindle_duration: 0.5  # seconds – minimum duration to count as a spindle
  max_spindle_gap: 0.2       # seconds – max gap to merge adjacent spindle segments

# Model Configuration
model:
  name: "SpindleCNN"   # Model type: SpindleCNN or UNet1D
  dropout_rate: 0.4    # Dropout rate for model layers

  # SpindleCNN specific
  n_channels: 16

  # UNet1D specific
  init_features: 64

# Training Configuration
training:
  epochs: 100
  batch_size: 32
  learning_rate: 0.001
  weight_decay: 0.0001
  patience: 15
  min_delta: 0.001

  # Loss function and parameters
  loss_function: "bce"   # Options: bce, focal, weighted_bce
  focal_alpha: 0.25      # (for focal loss)
  focal_gamma: 2.0       # (for focal loss)
  pos_weight: null       # Positive class weight (auto-calculated if null)

  # Optimizer and scheduler
  optimizer: "adam"      # Options: adam, sgd, adamw
  scheduler: "plateau"   # Options: plateau, step, cosine

  # Gradient clipping
  grad_clip_norm: 0.5

# Evaluation Configuration
evaluation:
  # Threshold settings for evaluation
  test_thresholds: [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]
  default_threshold: 0.5
  optimize_metric: "f1_score"    # Metric for finding optimal threshold (e.g., f1_score)

  segment_tolerance: 0.5         # seconds – tolerance for segment-based matching in evaluation

# Visualization Configuration
visualization:
  save_plots: true
  plot_format: "png"        # png, pdf, svg
  plot_dpi: 300

  # Which plots to generate
  plot_predictions_timeline: true
  plot_confusion_matrix: true
  plot_roc_curve: true
  plot_pr_curve: true
  plot_threshold_analysis: true

# Hardware Configuration
hardware:
  device: "auto"    # auto, cpu, cuda, mps
  num_workers: 4
  pin_memory: true

# Logging Configuration
logging:
  level: "INFO"                 # logging level (DEBUG, INFO, WARNING, ERROR)
  log_file: "logs/training.log"
  log_gradients: false          # whether to log model gradients to wandb
  log_every_n_steps: 100        # logging frequency (steps)
  save_model_every_n_epochs: 10 # checkpoint frequency (epochs)

# Reproducibility
seed: 42

# Advanced Configuration
advanced:
  checkpoint_monitor: "val_f1_score"   # metric to monitor for early stopping and checkpointing
  early_stopping_mode: "max"          # 'max' if monitor is a metric to maximize, 'min' if to minimize
  augmentation:
    noise_std: 0.01                   # standard deviation for Gaussian noise augmentation
    time_shift_max: 0.1               # max time shift as fraction of window length (for circular shift)
    amplitude_scale_range: [0.9, 1.1] # range for random amplitude scaling
