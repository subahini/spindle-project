model:
  name: stgcn_spindle
  C: 19
  T: 400
  F0: 16
  block_channels: [32, 48, 64]
  dilations: [1, 2, 4]
  dropout: 0.1
  se_ratio: 4

graph:
  prior: distance
  coords_csv: ./metadata/coords_10-20.csv
  channel_names: ["C3", "C4", "O1", "O2", "Fp1", "Fp2", "F7", "F3", "Fz", "F4", "F8",
                  "T3", "T4", "T5", "T6", "P3", "Pz", "P4", "Oz"]
  normalize: true
  sigma: 0.15
  lambda_init: 0.0
  use_dynamic: true
  beta_init: 0.1

loss:
  det_weight: 1.0
  dice:
    enabled: true
    weight: 0.5
  per_channel:
    enabled: false
    weight: 0.3
  bce:
    pos_weight: 5.0

train:
  optimizer: adamw
  lr: 1e-3
  weight_decay: 1e-4
  scheduler: onecycle
  epochs: 30
  batch_size: 64
  grad_clip: 1.0
  sampler:
    positive_fraction: 0.6

data:
  windows_npy: ./data/windows.npy
  labels_framewise: ./data/labels_framewise.npy
  labels_per_channel: ./data/labels_per_channel.npy
  sample_rate: 200
  val_fraction: 0.2

logging:
  wandb:
    enabled: true
    project: spindle_stgcn
    entity: "subahininadarajh-basel-university"
    run_name:
  save_every_epochs: 1
  eval_metrics_every_epochs: 5
  detection_threshold: 0.5
  log_graphs: true

# W&B Sweep Configuration - Limited to 50 runs
sweep:
  enabled: true
  method: bayes
  count: 50  # Maximum 50 runs

  metric:
    name: val/f1
    goal: maximize

  parameters:
    train.lr:
      distribution: log_uniform_values
      min: 0.00001
      max: 0.005

    train.weight_decay:
      values: [0.0, 0.001, 0.01, 0.05]

    train.batch_size:
      values: [32, 64, 128]

    train.sampler.positive_fraction:
      values: [0.4, 0.5, 0.6, 0.7]

    loss.bce.pos_weight:
      values: [3.0, 5.0, 7.0, 10.0]

    loss.dice.enabled:
      values: [true, false]

    loss.dice.weight:
      values: [0.3, 0.5, 0.7]

    model.dropout:
      values: [0.0, 0.1, 0.2]

    graph.use_dynamic:
      values: [true, false]

    graph.sigma:
      values: [0.1, 0.15, 0.2]